{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "sns.set(style='white', context='notebook', palette='deep')\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train[\"label\"]\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and the validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPkAAAD3CAYAAADfRfLgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104633c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[9][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (28,28,1)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = SGD(lr=0.01, momentum=0.0, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 239s - loss: 1.8614 - acc: 0.3410 - val_loss: 0.5711 - val_acc: 0.8802\n",
      "Epoch 2/5\n",
      " - 237s - loss: 0.7687 - acc: 0.7502 - val_loss: 0.1810 - val_acc: 0.9483\n",
      "Epoch 3/5\n",
      " - 237s - loss: 0.4286 - acc: 0.8657 - val_loss: 0.1335 - val_acc: 0.9617\n",
      "Epoch 4/5\n",
      " - 235s - loss: 0.3319 - acc: 0.8983 - val_loss: 0.1050 - val_acc: 0.9676\n",
      "Epoch 5/5\n",
      " - 238s - loss: 0.2716 - acc: 0.9168 - val_loss: 0.0952 - val_acc: 0.9717\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        0\n",
       "2        9\n",
       "3        0\n",
       "4        3\n",
       "5        7\n",
       "6        0\n",
       "7        3\n",
       "8        0\n",
       "9        3\n",
       "10       5\n",
       "11       7\n",
       "12       4\n",
       "13       0\n",
       "14       4\n",
       "15       3\n",
       "16       3\n",
       "17       1\n",
       "18       9\n",
       "19       0\n",
       "20       9\n",
       "21       1\n",
       "22       1\n",
       "23       5\n",
       "24       7\n",
       "25       4\n",
       "26       2\n",
       "27       7\n",
       "28       4\n",
       "29       7\n",
       "        ..\n",
       "27970    5\n",
       "27971    0\n",
       "27972    4\n",
       "27973    8\n",
       "27974    0\n",
       "27975    3\n",
       "27976    6\n",
       "27977    0\n",
       "27978    1\n",
       "27979    9\n",
       "27980    3\n",
       "27981    1\n",
       "27982    1\n",
       "27983    0\n",
       "27984    4\n",
       "27985    5\n",
       "27986    2\n",
       "27987    2\n",
       "27988    9\n",
       "27989    6\n",
       "27990    7\n",
       "27991    6\n",
       "27992    7\n",
       "27993    9\n",
       "27994    7\n",
       "27995    9\n",
       "27996    7\n",
       "27997    3\n",
       "27998    9\n",
       "27999    2\n",
       "Name: Label, Length: 28000, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.predict(test)\n",
    "# select with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
