{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from IPython.core.debugger import Tracer\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GAN(object):\n",
    "    \"\"\" Generative Adversarial Network class \"\"\"\n",
    "    def __init__(self, width=28, height=28, channels=1):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.channels = channels\n",
    "        self.shape = (self.width, self.height, self.channels)\n",
    "        self.optimizer = Adam(lr=0.01, beta_1=0.4, decay=8e-8)\n",
    "        self.G = self.__generator()\n",
    "        self.G.compile(loss='binary_crossentropy', optimizer=self.optimizer)\n",
    "        self.D = self.__discriminator()\n",
    "        self.D.compile(loss='binary_crossentropy', optimizer=self.optimizer, metrics=['accuracy'])\n",
    "        self.stacked_generator_discriminator = self.__stacked_generator_discriminator()\n",
    "        self.stacked_generator_discriminator.compile(loss='binary_crossentropy', optimizer=self.optimize\n",
    "    def __generator(self):\n",
    "        \"\"\" Declare generator \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_shape=(100,)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.7))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.7))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.7))\n",
    "        model.add(Dense(self.width  * self.height * self.channels, activation='tanh'))\n",
    "        model.add(Reshape((self.width, self.height, self.channels)))\n",
    "        return model\n",
    "    def __discriminator(self):\n",
    "        \"\"\" Declare discriminator \"\"\"\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=self.shape))\n",
    "        model.add(Dense((self.width * self.height * self.channels), input_shape=self.shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense((self.width * self.height * self.channels)/2))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "        return model\n",
    "    def __stacked_generator_discriminator(self):\n",
    "        self.D.trainable = False\n",
    "        model = Sequential()\n",
    "        model.add(self.G)\n",
    "        model.add(self.D)\n",
    "        return model\n",
    "    def train(self, X_train, epochs=20000, batch = 32, save_interval = 100):\n",
    "        for cnt in range(epochs):\n",
    "            ## train discriminator\n",
    "            random_index = np.random.randint(0, len(X_train) - batch/2)\n",
    "            legit_images = X_train[random_index : random_index + batch/2].reshape(batch/2, self.width, self.height, self.channels)\n",
    "            gen_noise = np.random.normal(0, 1, (batch/2, 100))\n",
    "            syntetic_images = self.G.predict(gen_noise)\n",
    "            x_combined_batch = np.concatenate((legit_images, syntetic_images))\n",
    "            y_combined_batch = np.concatenate((np.ones((batch/2, 1)), np.zeros((batch/2, 1))))\n",
    "            d_loss = self.D.train_on_batch(x_combined_batch, y_combined_batch)\n",
    "            # train generator\n",
    "            noise = np.random.normal(0, 1, (batch, 100))\n",
    "            y_mislabled = np.ones((batch, 1))\n",
    "            g_loss = self.stacked_generator_discriminator.train_on_batch(noise, y_mislabled)\n",
    "            print ('epoch: %d, [Discriminator :: d_loss: %f], [ Generator :: loss: %f]' % (cnt, d_loss[0], g_loss))\n",
    "            if cnt % save_interval == 0:\n",
    "                self.plot_images(save2file=True, step=cnt)\n",
    "    def plot_images(self, save2file=False, samples=16, step=0):\n",
    "        ''' Plot and generated images '''\n",
    "        filename = \"./images/mnist_%d.png\" % step\n",
    "        noise = np.random.normal(0, 1, (samples, 100))\n",
    "        images = self.G.predict(noise)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(4, 4, i+1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.height, self.width])\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
